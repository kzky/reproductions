# [WIP] Self-Attention Generative Adversarial Networks

This is the reproduction works, `Self-Attention Generative Adversarial Networks`.

Self-Attention Generative Adversarial Networks (SAGANs) is the good example since it contains many recently proposed techniqeus for GANs to stabilize trainin and produce high-quality, faithful samples. The following techniques are included in this SAGANs example.


- Spectral normalization
- Two Time-Scale Update Rule (TTUR)
- Self-Attention
- cGANs with Projection Discriminator
- Conditional Batch Normlaization (CBN)

[TODO]
- Add brief explanation for each techniques
- Add how to train
- Add how to generate
- Add how to evaluate


# References (paper)
1. Self-Attention Generative Adversarial Networks
2. Spectral Normalization For Generative Adversarial Networks
3. GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium
4. Non-local Neural Networks
5. cGANs with Projection Discriminator

# References (code)
1. https://github.com/pfnet-research/sngan_projection
2. https://github.com/rosinality/sagan-pytorch
3. https://github.com/taki0112/Self-Attention-GAN-Tensorflow
